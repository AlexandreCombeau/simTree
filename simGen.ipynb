{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np \n",
    "from functools import reduce \n",
    "import typing\n",
    "from copy import deepcopy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###---------------------------------------------------------------------###\n",
    "###-------------------------------------> Helper functions\n",
    "\n",
    "def f(a : str) -> str:\n",
    "    return a+\"o\"\n",
    "def g(a : str) -> str:\n",
    "    return a+\"K\"\n",
    "def h(a : str) -> str:\n",
    "    return a+a\n",
    "def ag1(a : str, b : str) -> str:\n",
    "    return a+\"-\"+b\n",
    "def ag2(a : str, b : str) -> str:\n",
    "    return b+\"-\"+a\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Self, Union\n",
    "import random\n",
    "\n",
    "rootType = Callable[[str,str], float]\n",
    "nodeType = Callable[[str], str]\n",
    "leafType = str\n",
    "\n",
    "#TODO refactor lambda functions\n",
    "\n",
    "class SimTree():\n",
    "\n",
    "    def __init__(self, value : leafType | nodeType | rootType = None, child : list = None):\n",
    "        self.value = value \n",
    "        self.child = child or []\n",
    "        self.isRoot = lambda x: True if(len(x.child) == 2) else False\n",
    "        self.isNode = lambda x: True if(len(x.child) == 1) else False\n",
    "        self.isLeaf = lambda x: True if(len(x.child) == 0) else False\n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        if self.isRoot(self): #root \n",
    "            tree_list = str([self.value.__name__,\n",
    "                         self.child[0].__str__(),\n",
    "                         self.child[1].__str__()])\n",
    "        elif self.isNode(self): #nodes\n",
    "            tree_list = [self.value.__name__,self.child[0].__str__()]\n",
    "        else: #leaf\n",
    "            tree_list = self.value\n",
    "        return tree_list  \n",
    "\n",
    "    def __eq__(self, other : Self) -> bool:\n",
    "        if self.isRoot(self) and other.isRoot(other):\n",
    "            return ((self.child[0].get_depth() == other.child[0].get_depth()) and \n",
    "                    (self.child[1].get_depth() == other.child[1].get_depth())\n",
    "                    ) and (self.value == other.value) and (self.child[0].__eq__(other.child[0]))\n",
    "        elif self.isNode(self) and other.isNode(other):\n",
    "            return (self.value == other.value) and self.child[0].__eq__(other.child[0])\n",
    "        else: \n",
    "            return True\n",
    "          \n",
    "    def return_tree_asList(self) -> list[Union[leafType, nodeType, rootType]]:\n",
    "        if self.isRoot(self): #root \n",
    "            tree_list = [self.value,\n",
    "                         self.child[0].return_tree_asList(),\n",
    "                         self.child[1].return_tree_asList()]\n",
    "        elif self.isNode(self): #nodes\n",
    "            tree_list = [self.value,self.child[0].return_tree_asList()]\n",
    "        else: #leaf\n",
    "            tree_list = self.value \n",
    "        return tree_list\n",
    "      \n",
    "    def compute(self) -> float:\n",
    "        if self.isRoot(self): #root\n",
    "            similarity = self.value(self.child[0].compute(),self.child[1].compute())\n",
    "            return similarity\n",
    "        elif self.isNode(self): #nodes\n",
    "            return self.value(self.child[0].compute())\n",
    "        else: #leaf\n",
    "            return self.value\n",
    "\n",
    "    def set_leaf_value(self,value : str) -> None:\n",
    "        if self.isNode(self):\n",
    "            self.child[0].set_leaf_value(value)\n",
    "        if self.isLeaf(self):\n",
    "            self.value = value\n",
    "\n",
    "    def set_leafs_value(self,values : list[str]) -> None:\n",
    "        x,y = values\n",
    "        self.child[0].set_leaf_value(x)\n",
    "        self.child[1].set_leaf_value(y)\n",
    "\n",
    "    def get_Similarity_function(self) -> rootType:\n",
    "        if self.isRoot(self): #root\n",
    "            return self.value\n",
    "        \n",
    "    def get_transformations_functions(self) -> list[nodeType]:\n",
    "        flatten = lambda l : [item for sublist in l for item in sublist]\n",
    "        if self.isRoot(self) == 2: #root\n",
    "            return flatten([self.child[0].get_transformations_functions,\n",
    "                            self.child[1].get_transformations_functions])\n",
    "\n",
    "        elif self.isNode(self) == 1: #nodes\n",
    "            return self.value\n",
    "\n",
    "    def find_depth(self,x : int) -> int:\n",
    "        x+=1\n",
    "        if self.isRoot(self):\n",
    "            return max(self.child[0].find_depth(x), self.child[1].find_depth(x))\n",
    "        if self.isNode(self):\n",
    "            return self.child[0].find_depth(x)\n",
    "        if self.isLeaf(self):\n",
    "            return x    \n",
    "\n",
    "    def get_depth(self) -> int:\n",
    "        return self.find_depth(0)    \n",
    "\n",
    "\n",
    "def tree_from_list(tree_list : list) -> SimTree:\n",
    "    if len(tree_list) == 3: #root\n",
    "        value = tree_list[0]\n",
    "        left_child = tree_list[1]\n",
    "        right_child = tree_list[2]\n",
    "        return SimTree(value,\n",
    "                [tree_from_list(left_child),\n",
    "                tree_from_list(right_child)])\n",
    "    elif len(tree_list) == 2: #nodes        \n",
    "        value = tree_list[0]\n",
    "        child = tree_list[1]\n",
    "        return SimTree(value,[tree_from_list(child)])\n",
    "    else: #leaf\n",
    "        value = tree_list[0]\n",
    "        return SimTree(value,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Combal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Combal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Combal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from similarity import *\n",
    "from transformation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMATION_FUNCTIONS = transformation_functions()           \n",
    "SIMILARITY_FUNCTIONS = similarity_functions()\n",
    "           \n",
    "flatten = lambda l : [item for sublist in l for item in sublist]\n",
    "def get_rd_function(nb_child,value):\n",
    "    if nb_child == 2:\n",
    "        function_list = SIMILARITY_FUNCTIONS\n",
    "    else:\n",
    "        function_list = TRANSFORMATION_FUNCTIONS\n",
    "    flag = True\n",
    "    while flag:\n",
    "        new_value = random.choice(function_list)\n",
    "        if new_value != value:\n",
    "            flag = False\n",
    "    return new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dates = [\n",
    "    '2006-10-28', '2005-11-15', '1936-11-07', '1955-09-08', '1936-12-07',\n",
    "    '1937-04-12', '1974-12-02', '1972-06-30', '1955-07-06', '2006-09-09',\n",
    "    '2007-11-06', '2007-11-13', '2009-09-29', '2014-03-25', '2001-12-04',\n",
    "    '2004-09-06', '2004-11-10', '2004-11-23', '2004-12-09', '2005-09-27',\n",
    "    '2011-09-27', '2000-09-12', '1999-09-14', '2003-11-11', '2004-02-05',\n",
    "    '2006-04-04', '2005-11-16', '2005-11-24', '2008-09-23', '2010-10-19',\n",
    "    '2005-09-13', '2005-09-14', '2006-03-07', '2009-09-08', '2011-11-01',\n",
    "    '2003-06-03', '1969-02-10', '2017-04-28', '2022-10-24', '2004-05-10',\n",
    "    '2018-03-14', '2002-04-11', '2013-03-09'\n",
    "]\n",
    "\n",
    "american_dates = []\n",
    "european_dates = []\n",
    "\n",
    "for date_str in dates:\n",
    "    date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    american_date = date_obj.strftime('%m/%d/%Y')\n",
    "    american_dates.append(american_date)\n",
    "    european_date = date_obj.strftime('%d/%m/%Y')\n",
    "    european_dates.append(european_date)\n",
    "\n",
    "# Print the converted dates\n",
    "values = []\n",
    "for a,e in zip(american_dates,european_dates):\n",
    "    #print(a+\" - \"+e)\n",
    "    values.append((a,e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimGen():\n",
    "    def __init__(self, param_algo : dict , param_data : dict):\n",
    "        #main param\n",
    "        self.population_size : int = param_algo[\"population_size\"]\n",
    "        self.nb_generation   : int = param_algo[\"nb_generation\"]\n",
    "        \n",
    "        \n",
    "        #evolution param\n",
    "        self.proba_mutation  : float = param_algo[\"proba_mutation\"]\n",
    "        self.proba_crossover : float = param_algo[\"proba_crossover\"]\n",
    "        self.proba_random_tree : float = param_algo[\"proba_random\"]\n",
    "        self.mutation_population_size    : int = round(self.proba_mutation*self.population_size)\n",
    "        self.crossover_population_size   : int = round(self.proba_crossover*self.population_size)\n",
    "        self.random_tree_population_size : int = round(self.proba_random_tree*self.population_size)\n",
    "        self.elitism_population_size     : int = self.population_size - (\n",
    "            self.mutation_population_size+\n",
    "            self.crossover_population_size+\n",
    "            self.random_tree_population_size\n",
    "        )\n",
    "        #self.proba_ellitism  : float = param_algo[\"proba_ellitism\"] #proba to keep best elem\n",
    "\n",
    "        #candidate param\n",
    "        self.tree_max_depth : int = param_data[\"tree_max_depth\"]\n",
    "\n",
    "        #init param\n",
    "        #TODO implement diff types of population in evolution\n",
    "        self.population : list[SimTree] = [] #current population\n",
    "        self.population_new : list[SimTree] = [] #previous population\n",
    "        self.population_scores : list[int] = [0]*self.population_size #every candidate has a score computed at the end of an generation\n",
    "        self.similarity_functions : list[rootType] = param_data[\"similarity_functions\"] \n",
    "        self.transformation_functions : list[nodeType] = param_data[\"transformation_functions\"]\n",
    "\n",
    "        #values param\n",
    "        self.values : list[tuple[str,str]] = param_data[\"values\"] #[(x1,y1),(x2,y2)...,(xn,yn)] such as (ei,p,xi) <=> (e'i,p',yi)\n",
    "\n",
    "    def generate_random_tree(self):\n",
    "        nb_transformation = random.randint(1,self.tree_max_depth)\n",
    "        tf_left = np.random.choice(self.transformation_functions,nb_transformation,replace=False)\n",
    "        tf_left = np.append(tf_left,[\"a\"]) #TODO check comment mieux gerer le lift\n",
    "        tf_right = np.random.choice(self.transformation_functions,nb_transformation,replace=False)\n",
    "        tf_right = np.append(tf_right,[\"a\"])\n",
    "        sf = np.random.choice(self.similarity_functions,1)[0]\n",
    "        def nest_list(lst):\n",
    "            #format our list of function : [f,g,h,...]\n",
    "            #into : [f,[g,[h,[...]]]]\n",
    "            if len(lst) == 1:\n",
    "                return [lst[0]]\n",
    "            else:\n",
    "                return [lst[0], nest_list(lst[1:])]\n",
    "\n",
    "        tree_list = [sf,nest_list(tf_left),nest_list(tf_right)]\n",
    "        tree = tree_from_list(tree_list)\n",
    "        return tree\n",
    "\n",
    "    def init_population(self):\n",
    "        \"\"\"\n",
    "            Generate a population of size n with random tree\n",
    "        \n",
    "        \"\"\"\n",
    "        #check variance and stuff meta data TODO\n",
    "        for _ in range(self.population_size):\n",
    "            self.population.append(self.generate_random_tree())\n",
    "    \n",
    "    #TODO add regularisation parameter\n",
    "    def fitness_function(self):\n",
    "        '''\n",
    "            Compute the score of a tree on every value pair\n",
    "            Keep the mean as a score\n",
    "        '''    \n",
    "         \n",
    "        for index,candidate in enumerate(self.population):\n",
    "            for values in self.values:\n",
    "                #compute score for each value pair for one tree\n",
    "                candidate.set_leafs_value(values)\n",
    "                score = candidate.compute()\n",
    "                self.population_scores[index] += score\n",
    "            self.population_scores[index] /= len(self.values)\n",
    "            if self.population_scores[index] > 1:\n",
    "                self.population_scores[index] = 1\n",
    "            \n",
    "    #TODO add loger to track evolution change\n",
    "    def mutation(self):\n",
    "        mutation_candiate = np.random.choice(self.population,self.mutation_population_size,replace=True)\n",
    "        for candidate in mutation_candiate:\n",
    "            root_pointer = deepcopy(candidate)\n",
    "            tree = root_pointer\n",
    "            #print(root_pointer)\n",
    "            invalid_mutation = True\n",
    "            while invalid_mutation:\n",
    "                mutation_type = np.random.choice([\"add\",\"modify\",\"remove\"])\n",
    "                if mutation_type ==\"remove\":\n",
    "                    #if condition not correct we loop because we cannot remove every transformation function\n",
    "                    invalid_mutation = tree.child[0].get_depth() <= 2 or tree.child[1].get_depth() <= 2\n",
    "                else: \n",
    "                    invalid_mutation = False\n",
    "            #print(mutation_type)\n",
    "            match mutation_type:\n",
    "                case \"modify\":\n",
    "                    if np.random.choice(['root','nodes']) == 'nodes':\n",
    "                        #print(\"change node\")\n",
    "                        tree = np.random.choice(tree.child) #choose left or right branche\n",
    "                        max_depth = tree.get_depth() - 1 #minus leaf, 0 is current node, 1 is next node ... etc\n",
    "                        depth_choice = np.random.choice(max_depth,1)[0]\n",
    "                        while depth_choice > 0:\n",
    "                            tree = tree.child[0]\n",
    "                            depth_choice -=1\n",
    "                        #depth_choice should be 0\n",
    "                    #else:\n",
    "                        #print(\"change root\")\n",
    "                    tree.value = get_rd_function(len(tree.child),tree.value)\n",
    "\n",
    "                case \"add\":\n",
    "                    child_choice = np.random.choice([0,1]) #choose left or right branche\n",
    "                    tree = tree.child[child_choice]\n",
    "                    max_depth = tree.get_depth()\n",
    "                    target_depth = np.random.choice(max_depth,1)[0]\n",
    "                    #print(\"target_depth\",target_depth)\n",
    "                    #print(\"max depth\", tree.get_depth())\n",
    "                    before = 0 #we need to insert a node before the current one, i.e : a new node conected to the root\n",
    "                    after  = 1 # we keep track of depths, we stop if we find our target depth\n",
    "                    while before != target_depth and after != target_depth: #if after find target or before already is target\n",
    "                        tree = tree.child[0]\n",
    "                        after  += 1\n",
    "                    #we found our target depth\n",
    "                    #print(f\"after : {after}, before {before}\")\n",
    "                    if before == target_depth: #we need to add a node connected to the root\n",
    "                        _tmp = root_pointer.child[child_choice]\n",
    "                        root_pointer.child[child_choice] = SimTree(get_rd_function(len(_tmp.child),None), [_tmp])\n",
    "                    if after == target_depth: #we add a new node after the current\n",
    "                        _tmp = tree.child[0]\n",
    "                        tree.child[0] = SimTree(get_rd_function(len(_tmp.child),None),[_tmp])\n",
    "\n",
    "                case \"remove\":\n",
    "                    child_choice = np.random.choice([0,1]) #choose left or right branche\n",
    "                    #print(f\"child choice : {'left' if child_choice else 'right'}\")\n",
    "                    before_pointer = tree\n",
    "                    tree = tree.child[child_choice]\n",
    "                    max_depth = tree.get_depth() - 1\n",
    "                    target_depth = np.random.choice(max_depth,1)[0]\n",
    "                    while target_depth != 0:\n",
    "                        before_pointer = tree\n",
    "                        tree = tree.child[0]\n",
    "                        target_depth -=1\n",
    "                    #we found our target depth\n",
    "                    #print(f\"target_depth : {target_depth}\")\n",
    "                    #link previous child we after child\n",
    "                    before_pointer.child[0] = tree.child[0]\n",
    "\n",
    "            self.population_new.append(root_pointer) #append new created element\n",
    "\n",
    "    #TODO if odd number, last index tuple will contain same index twice \n",
    "    def crossover(self):\n",
    "        #TODO ajouter où les nouveaux arbres\n",
    "        crossover_candidates = zip(\n",
    "            (candidate_list := np.random.choice(self.population,self.crossover_population_size*2,replace=False))[0:self.crossover_population_size],\n",
    "            candidate_list[self.crossover_population_size+1:-1])\n",
    "        for t1,t2 in crossover_candidates:\n",
    "            node_choice = [\n",
    "                [deepcopy(t1.child[0]), deepcopy(t2.child[1])],\n",
    "                [deepcopy(t2.child[0]), deepcopy(t1.child[1])],\n",
    "            ]\n",
    "            new_root_value = np.random.choice([t1.value,t2.value])\n",
    "            new_tree = SimTree(new_root_value,node_choice[np.random.choice(2)])\n",
    "            self.population_new.append(new_tree)\n",
    "        \n",
    "    def elitism(self):\n",
    "\n",
    "        #select best individuals\n",
    "        score_index = list(np.argsort(self.population_scores))\n",
    "        score_index.reverse()\n",
    "        #elitism population\n",
    "        best_individuals = [self.population[index] for index in score_index[0:self.elitism_population_size]]\n",
    "        #remove best elem from population\n",
    "        self.population_new = np.append(self.population_new,best_individuals).tolist()\n",
    "        #mutation population\n",
    "\n",
    "    def random_selection(self):\n",
    "        for tree in np.random.choice(self.population,self.random_tree_population_size):\n",
    "            self.population_new.append(tree)           \n",
    "    def save_state(self):\n",
    "        pass\n",
    "\n",
    "    def load_state(self):\n",
    "        pass\n",
    "\n",
    "    def evolve_population(self, load= False):\n",
    "        #compute score for each tree\n",
    "        self.init_population()\n",
    "        if load:\n",
    "            self.load_state()\n",
    "        for i in range(self.nb_generation):\n",
    "            self.save_state()\n",
    "            self.fitness_function()\n",
    "            self.mutation()\n",
    "            self.crossover()\n",
    "            self.random_selection()\n",
    "            self.elitism()\n",
    "\n",
    "\n",
    "  \n",
    "            \n",
    "     \n",
    "    #TODO crossover\n",
    "    #TODO add log to show trace of evolution for candidates\n",
    "    #TODO implement duel for elitism\n",
    "    #TODO add meta analyse de la taille des arbres et des types de fonctions utilisées\n",
    "    #TODO maybe add constraint to force each operation to take new elem, (just check with index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def remove_elem(pop : list,score_pop : list,index_list : list[int]) -> None:\n",
    "    for i in index_list:\n",
    "        pop.remove(i)\n",
    "        score_pop.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_algo = {\n",
    "    \"population_size\" : 100,\n",
    "    \"nb_generation\"   : 5,\n",
    "    \"proba_mutation\"  : 0.3,\n",
    "    \"proba_crossover\" : 0.2,\n",
    "    \"proba_random\"    : 0.1,\n",
    "    #\"proba_ellitism\"  : 0.4\n",
    "}\n",
    "\n",
    "param_data = {\n",
    "    \"tree_max_depth\" : 8,\n",
    "    \"similarity_functions\" : similarity_functions(),\n",
    "    \"transformation_functions\" : transformation_functions(),\n",
    "    \"values\" : values\n",
    "}\n",
    "\n",
    "\n",
    "sim = SimGen(param_algo,param_data)\n",
    "sim.evolve_population()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cos_similarity', ['stem', ['flatten', ['uppercase', ['lowercase', ['remove_whitespace', ['remove_stopwords', '03/09/2013']]]]]], ['tokenize', ['strip_whitespace', ['stem', ['remove_whitespace', ['flatten', ['remove_stopwords', '09/03/2013']]]]]]]\n",
      "['jaccard_similarity', ['remove_stopwords', ['remove_whitespace', ['lowercase', ['remove_punctuation', '03/09/2013']]]], ['remove_whitespace', ['remove_stopwords', ['remove_punctuation', ['uppercase', '09/03/2013']]]]]\n",
      "['cos_similarity', ['uppercase', '03/09/2013'], ['strip_whitespace', '09/03/2013']]\n",
      "['jaccard_similarity', ['strip_whitespace', '03/09/2013'], ['lowercase', '09/03/2013']]\n",
      "['jaccard_similarity', ['flatten', '03/09/2013'], ['remove_stopwords', '09/03/2013']]\n",
      "['cos_similarity', ['flatten', ['uppercase', ['tokenize', ['stem', ['strip_whitespace', '03/09/2013']]]]], ['uppercase', ['strip_whitespace', ['stem', ['flatten', ['tokenize', '09/03/2013']]]]]]\n",
      "['jaccard_similarity', ['lowercase', ['remove_stopwords', '03/09/2013']], ['stem', ['remove_whitespace', '09/03/2013']]]\n",
      "['jaccard_similarity', ['remove_stopwords', ['tokenize', ['strip_whitespace', ['stem', ['lowercase', ['flatten', ['remove_whitespace', ['remove_punctuation', '03/09/2013']]]]]]]], ['flatten', ['uppercase', ['stem', ['strip_whitespace', ['remove_stopwords', ['remove_punctuation', ['tokenize', ['lowercase', '09/03/2013']]]]]]]]]\n",
      "['jaccard_similarity', ['stem', ['remove_whitespace', ['lowercase', '03/09/2013']]], ['tokenize', ['stem', ['flatten', '09/03/2013']]]]\n",
      "['jaccard_similarity', ['strip_whitespace', ['stem', ['lowercase', ['flatten', ['tokenize', '03/09/2013']]]]], ['strip_whitespace', ['stem', ['uppercase', ['tokenize', ['remove_stopwords', '09/03/2013']]]]]]\n",
      "['jaccard_similarity', ['remove_punctuation', ['flatten', ['strip_whitespace', ['uppercase', ['stem', '03/09/2013']]]]], ['lowercase', ['remove_whitespace', ['strip_whitespace', ['remove_punctuation', ['uppercase', '09/03/2013']]]]]]\n",
      "['cos_similarity', ['tokenize', ['flatten', ['strip_whitespace', ['uppercase', '03/09/2013']]]], ['lowercase', ['strip_whitespace', ['stem', ['tokenize', '09/03/2013']]]]]\n",
      "['jaccard_similarity', ['flatten', ['stem', ['lowercase', ['remove_punctuation', ['remove_stopwords', ['uppercase', ['tokenize', '03/09/2013']]]]]]], ['flatten', ['uppercase', ['remove_stopwords', ['strip_whitespace', ['tokenize', ['remove_punctuation', ['stem', '09/03/2013']]]]]]]]\n",
      "['cos_similarity', ['lowercase', ['remove_stopwords', ['uppercase', '03/09/2013']]], ['uppercase', ['strip_whitespace', ['remove_stopwords', '09/03/2013']]]]\n",
      "['jaccard_similarity', ['flatten', '03/09/2013'], ['uppercase', '09/03/2013']]\n",
      "['jaccard_similarity', ['lowercase', ['remove_punctuation', ['flatten', ['remove_stopwords', '03/09/2013']]]], ['strip_whitespace', ['remove_punctuation', ['flatten', ['tokenize', '09/03/2013']]]]]\n",
      "['jaccard_similarity', ['tokenize', ['flatten', ['stem', ['remove_stopwords', '03/09/2013']]]], ['flatten', ['remove_whitespace', ['tokenize', ['lowercase', '09/03/2013']]]]]\n",
      "['jaccard_similarity', ['strip_whitespace', ['remove_stopwords', ['flatten', ['remove_punctuation', ['tokenize', ['lowercase', ['uppercase', '03/09/2013']]]]]]], ['lowercase', ['remove_stopwords', ['remove_punctuation', ['stem', ['tokenize', ['remove_whitespace', ['strip_whitespace', '09/03/2013']]]]]]]]\n",
      "['jaccard_similarity', ['stem', ['tokenize', ['remove_stopwords', '03/09/2013']]], ['stem', ['remove_whitespace', ['strip_whitespace', '09/03/2013']]]]\n",
      "['cos_similarity', ['lowercase', ['uppercase', ['remove_whitespace', ['strip_whitespace', ['tokenize', ['remove_stopwords', '03/09/2013']]]]]], ['lowercase', ['tokenize', ['uppercase', ['strip_whitespace', ['remove_whitespace', ['flatten', '09/03/2013']]]]]]]\n",
      "['cos_similarity', ['lowercase', ['tokenize', '03/09/2013']], ['flatten', ['lowercase', '09/03/2013']]]\n",
      "['jaccard_similarity', ['tokenize', '03/09/2013'], ['remove_stopwords', '09/03/2013']]\n",
      "['jaccard_similarity', ['uppercase', ['remove_whitespace', ['remove_stopwords', ['remove_punctuation', ['flatten', ['tokenize', ['lowercase', ['stem', '03/09/2013']]]]]]]], ['strip_whitespace', ['tokenize', ['remove_punctuation', ['lowercase', ['remove_stopwords', ['uppercase', ['flatten', ['remove_whitespace', '09/03/2013']]]]]]]]]\n",
      "['jaccard_similarity', ['remove_whitespace', '03/09/2013'], ['stem', '09/03/2013']]\n",
      "['jaccard_similarity', ['strip_whitespace', ['remove_whitespace', ['remove_stopwords', ['remove_punctuation', ['stem', ['uppercase', ['flatten', '03/09/2013']]]]]]], ['remove_punctuation', ['flatten', ['lowercase', ['uppercase', ['tokenize', ['stem', ['strip_whitespace', '09/03/2013']]]]]]]]\n",
      "['jaccard_similarity', ['remove_whitespace', ['remove_stopwords', ['uppercase', ['flatten', ['tokenize', ['stem', ['strip_whitespace', ['remove_punctuation', '03/09/2013']]]]]]]], ['strip_whitespace', ['uppercase', ['stem', ['tokenize', ['remove_whitespace', ['remove_punctuation', ['lowercase', ['remove_stopwords', '09/03/2013']]]]]]]]]\n",
      "['jaccard_similarity', ['uppercase', ['tokenize', ['remove_whitespace', ['remove_punctuation', '03/09/2013']]]], ['uppercase', ['stem', ['remove_stopwords', ['remove_punctuation', '09/03/2013']]]]]\n",
      "['jaccard_similarity', ['remove_whitespace', ['uppercase', ['strip_whitespace', '03/09/2013']]], ['remove_stopwords', ['stem', ['lowercase', '09/03/2013']]]]\n"
     ]
    }
   ],
   "source": [
    "for i,v in enumerate(sim.population_scores):\n",
    "    if v==1:\n",
    "        print(sim.population[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.fitness_function()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_pop = list(map(lambda x: str(x),sim.population))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SimTree at 0x1bf9aea90d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [ag1,[g,\"a\"],[g,[g,[g,[\"b\"]]]]]\n",
    "b = [ag1,[f,[g,\"b\"]],[g,[g,[g,[\"b\"]]]]]\n",
    "tree = tree_from_list(a)\n",
    "tr = tree_from_list(b)\n",
    "np.random.choice([tree,tr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = [\n",
    "    '1234 Elm Street',\n",
    "    '567 Maple Avenue',\n",
    "    '789 Oak Drive',\n",
    "    '1011 Pine Lane',\n",
    "    '1213 Cedar Court',\n",
    "    '1415 Birch Road',\n",
    "    '1617 Willow Way',\n",
    "    '1819 Aspen Circle',\n",
    "    '2021 Juniper Street',\n",
    "    '2223 Spruce Avenue',\n",
    "    '2425 Alder Drive',\n",
    "    '2627 Chestnut Lane',\n",
    "    '2829 Poplar Court',\n",
    "    '3031 Magnolia Road',\n",
    "    '3233 Laurel Way',\n",
    "    '3435 Acacia Circle',\n",
    "    '3637 Sycamore Street',\n",
    "    '3839 Hickory Avenue',\n",
    "    '4041 Pinecone Drive',\n",
    "    '4243 Cedar Lane',\n",
    "    '4445 Birch Court',\n",
    "    '4647 Willow Road',\n",
    "    '4849 Aspen Way',\n",
    "    '5051 Juniper Avenue',\n",
    "    '5253 Spruce Drive',\n",
    "    '5455 Alder Court',\n",
    "    '5657 Chestnut Street',\n",
    "    '5859 Poplar Avenue',\n",
    "    '6061 Magnolia Lane',\n",
    "    '6263 Laurel Circle',\n",
    "    '6465 Acacia Road',\n",
    "    '6667 Sycamore Way',\n",
    "    '6869 Hickory Court',\n",
    "    '7071 Pinecone Street',\n",
    "    '7273 Cedar Avenue',\n",
    "    '7475 Birch Drive',\n",
    "    '7677 Willow Lane',\n",
    "    '7879 Aspen Court',\n",
    "    '8081 Juniper Road',\n",
    "    '8283 Spruce Way',\n",
    "    '8485 Alder Circle',\n",
    "    '8687 Chestnut Avenue',\n",
    "    '8889 Poplar Drive',\n",
    "    '9091 Magnolia Court',\n",
    "    '9293 Laurel Street',\n",
    "    '9495 Acacia Lane',\n",
    "    '9697 Sycamore Avenue',\n",
    "    '9899 Hickory Road',\n",
    "    '100101 Pinecone Way',\n",
    "    '102103 Cedar Court'\n",
    "]\n",
    "import random\n",
    "\n",
    "def add_noise(address):\n",
    "    address_parts = address.split()\n",
    "    for i in range(len(address_parts)):\n",
    "        part = address_parts[i]\n",
    "        if part.isdigit():\n",
    "            # Modify the numbers by adding or subtracting a small random value\n",
    "            num = int(part)\n",
    "            noise = random.randint(-5, 5)\n",
    "            address_parts[i] = str(num + noise)\n",
    "        else:\n",
    "            # Modify the names by randomly replacing a character with another\n",
    "            modified_part = ''\n",
    "            for char in part:\n",
    "                if random.random() < 0.1:  # 10% chance of modification\n",
    "                    modified_part += random.choice('abcdefghijklmnopqrstuvwxyz')\n",
    "                else:\n",
    "                    modified_part += char\n",
    "            address_parts[i] = modified_part\n",
    "    return ' '.join(address_parts)\n",
    "\n",
    "noisy_addresses = [add_noise(address) for address in addresses]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_algo = {\n",
    "    \"population_size\" : 100,\n",
    "    \"nb_generation\"   : 10,\n",
    "    \"proba_mutation\"  : 0.3,\n",
    "    \"proba_crossover\" : 0.2,\n",
    "    \"proba_random\"    : 0.1,\n",
    "    #\"proba_ellitism\"  : 0.4\n",
    "}\n",
    "\n",
    "param_data = {\n",
    "    \"tree_max_depth\" : 8,\n",
    "    \"similarity_functions\" : similarity_functions(),\n",
    "    \"transformation_functions\" : transformation_functions(),\n",
    "    \"values\" : values\n",
    "}\n",
    "# Print the converted dates\n",
    "values = []\n",
    "for a,e in zip(noisy_addresses,addresses):\n",
    "    #print(a+\" - \"+e)\n",
    "    values.append((a,e))\n",
    "\n",
    "\n",
    "sim = SimGen(param_algo,param_data)\n",
    "sim.evolve_population()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jaro_similarity', ['lowercase', ['flatten', ['remove_stopwords', '03/09/2013']]], ['stem', ['remove_whitespace', ['strip_whitespace', '09/03/2013']]]]\n",
      "['cos_similarity', ['stem', ['strip_whitespace', ['uppercase', '03/09/2013']]], ['remove_stopwords', ['lowercase', ['remove_whitespace', '09/03/2013']]]]\n",
      "['jaro_similarity', ['remove_punctuation', ['lowercase', ['stem', ['strip_whitespace', '03/09/2013']]]], ['stem', ['uppercase', ['strip_whitespace', ['remove_punctuation', '09/03/2013']]]]]\n",
      "['jaro_similarity', ['strip_whitespace', '03/09/2013'], ['stem', '09/03/2013']]\n",
      "['jaccard_similarity', ['flatten', ['strip_whitespace', ['tokenize', ['remove_stopwords', ['stem', ['remove_punctuation', ['remove_whitespace', ['lowercase', '03/09/2013']]]]]]]], ['uppercase', ['stem', ['remove_punctuation', ['tokenize', ['remove_whitespace', ['strip_whitespace', ['remove_stopwords', ['lowercase', '09/03/2013']]]]]]]]]\n",
      "['jaro_similarity', ['flatten', ['strip_whitespace', ['remove_stopwords', ['remove_punctuation', ['remove_whitespace', '03/09/2013']]]]], ['stem', ['remove_punctuation', ['strip_whitespace', ['uppercase', ['tokenize', '09/03/2013']]]]]]\n",
      "['jaro_similarity', ['stem', ['lowercase', ['remove_punctuation', ['flatten', ['remove_whitespace', ['remove_stopwords', ['tokenize', '03/09/2013']]]]]]], ['stem', ['tokenize', ['flatten', ['strip_whitespace', ['remove_whitespace', ['remove_punctuation', ['lowercase', '09/03/2013']]]]]]]]\n",
      "['cos_similarity', ['flatten', ['strip_whitespace', ['remove_whitespace', ['stem', ['lowercase', '03/09/2013']]]]], ['lowercase', ['remove_stopwords', ['remove_whitespace', ['flatten', ['stem', '09/03/2013']]]]]]\n",
      "['jaccard_similarity', ['strip_whitespace', ['remove_whitespace', ['tokenize', ['stem', '03/09/2013']]]], ['flatten', ['uppercase', ['stem', ['tokenize', '09/03/2013']]]]]\n",
      "['jaccard_similarity', ['strip_whitespace', ['tokenize', ['uppercase', ['remove_whitespace', ['lowercase', ['flatten', ['remove_stopwords', ['remove_punctuation', '03/09/2013']]]]]]]], ['tokenize', ['flatten', ['remove_whitespace', ['remove_punctuation', ['lowercase', ['remove_stopwords', ['strip_whitespace', ['stem', '09/03/2013']]]]]]]]]\n",
      "['cos_similarity', ['uppercase', ['tokenize', ['strip_whitespace', '03/09/2013']]], ['remove_whitespace', ['flatten', ['uppercase', '09/03/2013']]]]\n",
      "['jaro_similarity', ['remove_stopwords', ['remove_whitespace', ['strip_whitespace', ['remove_punctuation', ['uppercase', ['tokenize', '03/09/2013']]]]]], ['strip_whitespace', ['flatten', ['stem', ['remove_punctuation', ['remove_stopwords', ['tokenize', '09/03/2013']]]]]]]\n",
      "['jaccard_similarity', ['lowercase', ['flatten', ['remove_stopwords', ['strip_whitespace', ['stem', ['remove_whitespace', ['remove_punctuation', ['uppercase', '03/09/2013']]]]]]]], ['tokenize', ['flatten', ['remove_punctuation', ['remove_whitespace', ['uppercase', ['stem', ['remove_stopwords', ['strip_whitespace', '09/03/2013']]]]]]]]]\n",
      "['jaccard_similarity', ['flatten', ['strip_whitespace', ['tokenize', '03/09/2013']]], ['remove_stopwords', ['stem', ['uppercase', '09/03/2013']]]]\n",
      "['jaro_similarity', ['lowercase', ['flatten', ['tokenize', ['stem', ['remove_whitespace', ['remove_punctuation', ['strip_whitespace', '03/09/2013']]]]]]], ['flatten', ['uppercase', ['remove_whitespace', ['lowercase', ['remove_punctuation', ['remove_stopwords', ['stem', '09/03/2013']]]]]]]]\n",
      "['jaccard_similarity', ['stem', ['tokenize', ['remove_stopwords', ['remove_punctuation', ['lowercase', ['uppercase', ['flatten', ['remove_whitespace', '03/09/2013']]]]]]]], ['uppercase', ['strip_whitespace', ['tokenize', ['remove_punctuation', ['lowercase', ['flatten', ['stem', ['remove_whitespace', '09/03/2013']]]]]]]]]\n",
      "['jaccard_similarity', ['tokenize', '03/09/2013'], ['lowercase', '09/03/2013']]\n",
      "['jaccard_similarity', ['remove_stopwords', ['uppercase', ['strip_whitespace', ['stem', '03/09/2013']]]], ['strip_whitespace', ['lowercase', ['flatten', ['stem', '09/03/2013']]]]]\n",
      "['jaccard_similarity', ['flatten', ['remove_whitespace', ['stem', ['strip_whitespace', ['remove_punctuation', ['tokenize', ['uppercase', ['lowercase', '03/09/2013']]]]]]]], ['lowercase', ['uppercase', ['remove_whitespace', ['flatten', ['tokenize', ['remove_punctuation', ['remove_stopwords', ['stem', '09/03/2013']]]]]]]]]\n",
      "['jaccard_similarity', ['remove_punctuation', ['lowercase', ['strip_whitespace', ['tokenize', ['uppercase', '03/09/2013']]]]], ['remove_punctuation', ['flatten', ['uppercase', ['remove_stopwords', ['remove_whitespace', '09/03/2013']]]]]]\n",
      "['jaro_similarity', ['remove_stopwords', ['strip_whitespace', ['flatten', ['tokenize', '03/09/2013']]]], ['strip_whitespace', ['flatten', ['lowercase', ['tokenize', '09/03/2013']]]]]\n",
      "['cos_similarity', ['stem', '03/09/2013'], ['stem', '09/03/2013']]\n",
      "['jaccard_similarity', ['uppercase', '03/09/2013'], ['remove_stopwords', '09/03/2013']]\n",
      "['cos_similarity', ['tokenize', '03/09/2013'], ['strip_whitespace', '09/03/2013']]\n",
      "['jaccard_similarity', ['remove_stopwords', '03/09/2013'], ['strip_whitespace', '09/03/2013']]\n",
      "['jaccard_similarity', ['uppercase', ['lowercase', ['flatten', ['tokenize', '03/09/2013']]]], ['uppercase', ['remove_stopwords', ['flatten', ['remove_whitespace', '09/03/2013']]]]]\n",
      "['jaro_similarity', ['remove_punctuation', ['flatten', ['uppercase', ['lowercase', ['strip_whitespace', ['stem', ['remove_stopwords', ['remove_whitespace', '03/09/2013']]]]]]]], ['lowercase', ['flatten', ['remove_whitespace', ['stem', ['remove_punctuation', ['tokenize', ['remove_stopwords', ['strip_whitespace', '09/03/2013']]]]]]]]]\n",
      "['jaccard_similarity', ['tokenize', ['strip_whitespace', ['flatten', ['remove_punctuation', ['remove_whitespace', '03/09/2013']]]]], ['flatten', ['remove_punctuation', ['remove_stopwords', ['lowercase', ['uppercase', '09/03/2013']]]]]]\n",
      "['jaccard_similarity', ['lowercase', ['remove_punctuation', ['strip_whitespace', ['remove_stopwords', ['stem', '03/09/2013']]]]], ['tokenize', ['remove_punctuation', ['remove_stopwords', ['uppercase', ['strip_whitespace', '09/03/2013']]]]]]\n",
      "['jaro_similarity', ['flatten', ['tokenize', ['remove_stopwords', ['remove_punctuation', ['strip_whitespace', ['stem', ['lowercase', '03/09/2013']]]]]]], ['remove_punctuation', ['lowercase', ['remove_whitespace', ['tokenize', ['uppercase', ['remove_stopwords', ['flatten', '09/03/2013']]]]]]]]\n",
      "['jaro_similarity', ['stem', '03/09/2013'], ['lowercase', '09/03/2013']]\n",
      "['jaro_similarity', ['flatten', ['tokenize', ['strip_whitespace', ['remove_stopwords', ['remove_punctuation', ['uppercase', ['lowercase', '03/09/2013']]]]]]], ['strip_whitespace', ['remove_stopwords', ['remove_whitespace', ['remove_punctuation', ['lowercase', ['tokenize', ['flatten', '09/03/2013']]]]]]]]\n",
      "['cos_similarity', ['strip_whitespace', ['lowercase', '03/09/2013']], ['strip_whitespace', ['remove_whitespace', '09/03/2013']]]\n"
     ]
    }
   ],
   "source": [
    "for i,v in enumerate(sim.population_scores):\n",
    "    if v> 0.9 :\n",
    "        print(sim.population[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
